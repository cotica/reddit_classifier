{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping subreddits\n",
    "\n",
    "\n",
    "## Problem statement\n",
    "---\n",
    "We are producing a trivia focused, _Jeopardy_ or _Who Wants to Be a Millionaire_* style game show, where we want the audience to guess the source of the movie details. Everything is scrambled together! The task: figure out if the details came from good movie details, or whether the movie production team took a shorcut and landed in Sh**ty Movie Details!\n",
    "\n",
    "*Trademarks of their appropiate productions\n",
    "\n",
    "To do this, we are going to solve the problem using a classifer trained on some subreddit data.\n",
    "\n",
    "_Thanks to Gwen Rathgeber for some inspiration during the quest for a compelling problem statement!_\n",
    "\n",
    "![](https://www.bigraildiversity.co.uk/wp-content/uploads/2018/10/Night-at-the-Movies-Converted-900x600.png)\n",
    "\n",
    "\n",
    "## Data sources and references\n",
    "\n",
    "---\n",
    "\n",
    "1. GENERAL NOTE ON ATTRIBUTION: The work throughout this Report, including many if not most coding techniques, rely and borrow heavily from code discussed in Riley Dallas, Sophie \"Sonya\" Tabac, Charlie Rice, Heather Robbins, and Gwen Rathgeber's class lectures, Notebooks, GitHub repositories, tips on techniques and troubleshooting help. The code is adapted to solve our specific problem.\n",
    "\n",
    "\n",
    "2. The following subReddits were scraped:\n",
    "\n",
    "    * [Movie Details](https://www.reddit.com/r/MovieDetails/)\n",
    "    * [Sh**ty Movie Details](https://www.reddit.com/r/shittymoviedetails/)\n",
    "\n",
    "---\n",
    "\n",
    "### Note on the data and style\n",
    "\n",
    "Strong language may appear in various Reddit posts in raw form. To the extent possible, it shall be cleaned in the course of the project. There also may be some humor used throughout the presentation of the analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Webscrape - let's fetch some data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import all our required libraries up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:09.902745Z",
     "start_time": "2021-04-25T01:59:53.139161Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd, numpy as np, requests, time, nltk, datetime as dt\n",
    "\n",
    "#NLP\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import gensim.downloader as api #allows us to get word2vec anf glove embeddins that we need\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "#classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, plot_confusion_matrix, \\\n",
    "                             recall_score, precision_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "# easier to see full text with a bigger maxwidth:\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the PushShift API to collect the subReddit data we need.\n",
    "\n",
    "More information about the API can be found on the [Pushshift repo](https://github.com/pushshift/api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up single post scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:09.908350Z",
     "start_time": "2021-04-25T02:00:09.904705Z"
    }
   },
   "outputs": [],
   "source": [
    "#Query the PushShift API for the subReddit data we need\n",
    "url = 'https://api.pushshift.io/reddit/search/submission?subreddit=MovieDetails'\n",
    "url2 = 'https://api.pushshift.io/reddit/search/submission?subreddit=shittymoviedetails'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_PRO-TIP: We can paste the URL in browser to preview the JSON format._\n",
    "\n",
    "Next, we need to define some parameters and then confirm that we get a response from the API, from both the subReddits. (NOTE: There is no key needed to access the Reddit API.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:01:13.919972Z",
     "start_time": "2021-04-25T02:01:13.916059Z"
    }
   },
   "outputs": [],
   "source": [
    "#define what we need to get from the subreddit\n",
    "params = {\n",
    "    'subreddit': 'MovieDetails',\n",
    "    'size' : 100 #100 seems to be the max, even if change this to a greater size\n",
    "#    'before': ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:01:15.946693Z",
     "start_time": "2021-04-25T02:01:15.942718Z"
    }
   },
   "outputs": [],
   "source": [
    "#define what we need to get from the subreddit\n",
    "params2 = {\n",
    "    'subreddit': 'shittymoviedetails',\n",
    "    'size' : 100 #100 seems to be the max, even if change this to a greater size\n",
    "#    'before': ''\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that our response is valid -- we are looking for a 200 response code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:01:20.236906Z",
     "start_time": "2021-04-25T02:01:17.827271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(url, params) \n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:01:31.194299Z",
     "start_time": "2021-04-25T02:01:23.287238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = requests.get(url2, params2)\n",
    "res2.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the content we fetched, for a single post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:04:07.638584Z",
     "start_time": "2021-04-25T02:04:07.625146Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "{'all_awardings': [], 'allow_live_comments': False, 'author': 'October23rd2077', 'author_flair_css_class': None, 'author_flair_richtext': [], 'author_flair_text': None, 'author_flair_type': 'text', 'author_fullname': 't2_70rlnux8', 'author_patreon_flair': False, 'author_premium': False, 'awarders': [], 'can_mod_post': False, 'contest_mode': False, 'created_utc': 1619315293, 'domain': 'reddit.com', 'full_link': 'https://www.reddit.com/r/MovieDetails/comments/mxy6dk/in_cars_2006_the_king_strip_weathers_crashes_in/', 'gallery_data': {'items': [{'id': 40772735, 'media_id': 'n2933i7868v61'}, {'id': 40772736, 'media_id': '75dqji7868v61'}]}, 'gildings': {}, 'id': 'mxy6dk', 'is_crosspostable': True, 'is_gallery': True, 'is_meta': False, 'is_original_content': False, 'is_reddit_media_domain': False, 'is_robot_indexable': True, 'is_self': False, 'is_video': False, 'link_flair_background_color': '#0079d3', 'link_flair_css_class': 'Image', 'link_flair_richtext': [{'e': 'text', 't': 'ü•ö Easter Egg'}], 'link_flair_template_id': 'b968d6fa-5f2d-11e7-8e64-0e8c19beb1c6', 'link_flair_text': 'ü•ö Easter Egg', 'link_flair_text_color': 'light', 'link_flair_type': 'richtext', 'locked': False, 'media_metadata': {'75dqji7868v61': {'e': 'Image', 'id': '75dqji7868v61', 'm': 'image/jpg', 'p': [{'u': 'https://preview.redd.it/75dqji7868v61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04c4e6a71acefaf590fb03bb58c2cdf86b820628', 'x': 108, 'y': 87}, {'u': 'https://preview.redd.it/75dqji7868v61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dcf8e724ea30fe9703afdc61f504c93c484d13fa', 'x': 216, 'y': 175}, {'u': 'https://preview.redd.it/75dqji7868v61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a28f63e6cc592e5a39feb7716c4a2702f555d84', 'x': 320, 'y': 259}, {'u': 'https://preview.redd.it/75dqji7868v61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf64866768bce17758ace49246a03c834ef76e2b', 'x': 640, 'y': 518}], 's': {'u': 'https://preview.redd.it/75dqji7868v61.jpg?width=750&amp;format=pjpg&amp;auto=webp&amp;s=69d9eda379dfd9fd1f3b3b0fbe0c1a6b42e82d35', 'x': 750, 'y': 608}, 'status': 'valid'}, 'n2933i7868v61': {'e': 'Image', 'id': 'n2933i7868v61', 'm': 'image/jpg', 'p': [{'u': 'https://preview.redd.it/n2933i7868v61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c1b0fe20a94cef4ba7c1148cadb07d67194c29d', 'x': 108, 'y': 60}, {'u': 'https://preview.redd.it/n2933i7868v61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bea862922852ca3434c0c57ea364c99aaca884b4', 'x': 216, 'y': 121}, {'u': 'https://preview.redd.it/n2933i7868v61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d762ea93de451d44385faa639420a6e1921bd8cd', 'x': 320, 'y': 180}], 's': {'u': 'https://preview.redd.it/n2933i7868v61.jpg?width=320&amp;format=pjpg&amp;auto=webp&amp;s=174db8fa9431a8616be9acaad3681368b886f700', 'x': 320, 'y': 180}, 'status': 'valid'}}, 'media_only': False, 'no_follow': False, 'num_comments': 1, 'num_crossposts': 0, 'over_18': False, 'parent_whitelist_status': 'all_ads', 'permalink': '/r/MovieDetails/comments/mxy6dk/in_cars_2006_the_king_strip_weathers_crashes_in/', 'pinned': False, 'pwls': 6, 'retrieved_on': 1619315329, 'score': 1, 'selftext': '', 'send_replies': True, 'spoiler': False, 'stickied': False, 'subreddit': 'MovieDetails', 'subreddit_id': 't5_3md1s', 'subreddit_subscribers': 2288831, 'subreddit_type': 'public', 'suggested_sort': 'confidence', 'thumbnail': 'https://b.thumbs.redditmedia.com/q80HUaOYnPDm5UVp9mvCJ4d0kzfdswI9w8bir578gIA.jpg', 'thumbnail_height': 78, 'thumbnail_width': 140, 'title': 'In Cars (2006), ‚ÄúThe King‚Äù Strip Weathers crashes in his final race, but makes it to the finish line. In 1992, NASCAR‚Äôs ‚ÄúKing,‚Äù Richard Petty (the voice of Strip Weathers in the Cars movies), crashed in his final race but was able to finish the race thanks to repairs by his race team.', 'total_awards_received': 0, 'treatment_tags': [], 'upvote_ratio': 1.0, 'url': 'https://www.reddit.com/gallery/mxy6dk', 'url_overridden_by_dest': 'https://www.reddit.com/gallery/mxy6dk', 'whitelist_status': 'all_ads', 'wls': 6}\n",
      "<class 'dict'>\n",
      "dict_keys(['data'])\n"
     ]
    }
   ],
   "source": [
    "print(type(res)) #check attrs\n",
    "\n",
    "data = res.json() #get the content in JSON format\n",
    "\n",
    "posts = data['data'][0] #Fetch the list of first posts\n",
    "\n",
    "#verify what we got\n",
    "print(posts)\n",
    "\n",
    "print(type(posts))\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything we do, we have to repeat for our second subReddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:04:34.026591Z",
     "start_time": "2021-04-25T02:04:34.012395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_awardings': [],\n",
       " 'allow_live_comments': False,\n",
       " 'author': 'invertedparadX',\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'author_flair_text': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'author_fullname': 't2_8i9wni58',\n",
       " 'author_patreon_flair': False,\n",
       " 'author_premium': True,\n",
       " 'awarders': [],\n",
       " 'can_mod_post': False,\n",
       " 'contest_mode': False,\n",
       " 'created_utc': 1619315795,\n",
       " 'domain': 'i.redd.it',\n",
       " 'full_link': 'https://www.reddit.com/r/shittymoviedetails/comments/mxybxi/the_nineties_was_weird_bruh_goro_mortal_kombat/',\n",
       " 'gildings': {},\n",
       " 'id': 'mxybxi',\n",
       " 'is_crosspostable': True,\n",
       " 'is_meta': False,\n",
       " 'is_original_content': False,\n",
       " 'is_reddit_media_domain': True,\n",
       " 'is_robot_indexable': True,\n",
       " 'is_self': False,\n",
       " 'is_video': False,\n",
       " 'link_flair_background_color': '',\n",
       " 'link_flair_richtext': [],\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'link_flair_type': 'text',\n",
       " 'locked': False,\n",
       " 'media_only': False,\n",
       " 'no_follow': True,\n",
       " 'num_comments': 0,\n",
       " 'num_crossposts': 0,\n",
       " 'over_18': False,\n",
       " 'parent_whitelist_status': 'some_ads',\n",
       " 'permalink': '/r/shittymoviedetails/comments/mxybxi/the_nineties_was_weird_bruh_goro_mortal_kombat/',\n",
       " 'pinned': False,\n",
       " 'post_hint': 'image',\n",
       " 'preview': {'enabled': True,\n",
       "  'images': [{'id': 'mPYZB3l7kaPy1_kLc4H2dJDPCkO-QDhRf7NYukFQSq0',\n",
       "    'resolutions': [{'height': 157,\n",
       "      'url': 'https://preview.redd.it/8hadg72q78v61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a29216d5320698272251c6896168019f8a701429',\n",
       "      'width': 108},\n",
       "     {'height': 314,\n",
       "      'url': 'https://preview.redd.it/8hadg72q78v61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f4fa69ee44ea3f27abee4aa1ad71b2796bdfa28',\n",
       "      'width': 216},\n",
       "     {'height': 465,\n",
       "      'url': 'https://preview.redd.it/8hadg72q78v61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b6e23c4ccbf0c9ef2f7ce0c59653a760a7f7bde',\n",
       "      'width': 320}],\n",
       "    'source': {'height': 540,\n",
       "     'url': 'https://preview.redd.it/8hadg72q78v61.jpg?auto=webp&amp;s=e1cf17ace43d438f04d8030134cce119588a706e',\n",
       "     'width': 371},\n",
       "    'variants': {}}]},\n",
       " 'pwls': 7,\n",
       " 'retrieved_on': 1619315806,\n",
       " 'score': 1,\n",
       " 'selftext': '',\n",
       " 'send_replies': True,\n",
       " 'spoiler': False,\n",
       " 'stickied': False,\n",
       " 'subreddit': 'shittymoviedetails',\n",
       " 'subreddit_id': 't5_3mj3w',\n",
       " 'subreddit_subscribers': 600042,\n",
       " 'subreddit_type': 'public',\n",
       " 'suggested_sort': 'confidence',\n",
       " 'thumbnail': 'https://b.thumbs.redditmedia.com/cOf6xkXNAye8ayHS9YTUs_NiLKHHeuoWweUB9-uEIWs.jpg',\n",
       " 'thumbnail_height': 140,\n",
       " 'thumbnail_width': 140,\n",
       " 'title': '\"the nineties was weird bruh\" ‚Äî Goro (mortal kombat)',\n",
       " 'total_awards_received': 0,\n",
       " 'treatment_tags': [],\n",
       " 'upvote_ratio': 1.0,\n",
       " 'url': 'https://i.redd.it/8hadg72q78v61.jpg',\n",
       " 'url_overridden_by_dest': 'https://i.redd.it/8hadg72q78v61.jpg',\n",
       " 'whitelist_status': 'some_ads',\n",
       " 'wls': 7}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#repeat for the 2nd subreddit\n",
    "data2 = res2.json() #get the content in JSON format\n",
    "posts2 = data2['data'][0] #Fetch the list of first post\n",
    "posts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:05:22.440164Z",
     "start_time": "2021-04-25T02:05:22.433171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what we pulled in a more visually accessible format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:05:25.493710Z",
     "start_time": "2021-04-25T02:05:25.429561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>...</th>\n",
       "      <th>wls</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>preview</th>\n",
       "      <th>media</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>October23rd2077</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_70rlnux8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>coolstevenn</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_4g0p2x9c</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Letywolf</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_housnk8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>thewiseone91</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_71kxf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>thewiseone91</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_71kxf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings  allow_live_comments           author author_flair_css_class  \\\n",
       "0            []                False  October23rd2077                   None   \n",
       "1            []                False      coolstevenn                   None   \n",
       "2            []                False         Letywolf                   None   \n",
       "3            []                False     thewiseone91                   None   \n",
       "4            []                False     thewiseone91                   None   \n",
       "\n",
       "  author_flair_richtext author_flair_text author_flair_type author_fullname  \\\n",
       "0                    []              None              text     t2_70rlnux8   \n",
       "1                    []              None              text     t2_4g0p2x9c   \n",
       "2                    []              None              text      t2_housnk8   \n",
       "3                    []              None              text        t2_71kxf   \n",
       "4                    []              None              text        t2_71kxf   \n",
       "\n",
       "   author_patreon_flair  author_premium  ... wls  removed_by_category  \\\n",
       "0                 False           False  ...   6                  NaN   \n",
       "1                 False           False  ...   6                  NaN   \n",
       "2                 False           False  ...   6                  NaN   \n",
       "3                 False           False  ...   6                  NaN   \n",
       "4                 False           False  ...   6                  NaN   \n",
       "\n",
       "   post_hint  preview media media_embed secure_media secure_media_embed  \\\n",
       "0        NaN      NaN   NaN         NaN          NaN                NaN   \n",
       "1        NaN      NaN   NaN         NaN          NaN                NaN   \n",
       "2        NaN      NaN   NaN         NaN          NaN                NaN   \n",
       "3        NaN      NaN   NaN         NaN          NaN                NaN   \n",
       "4        NaN      NaN   NaN         NaN          NaN                NaN   \n",
       "\n",
       "  author_flair_template_id  author_flair_text_color  \n",
       "0                      NaN                      NaN  \n",
       "1                      NaN                      NaN  \n",
       "2                      NaN                      NaN  \n",
       "3                      NaN                      NaN  \n",
       "4                      NaN                      NaN  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create df\n",
    "results_df = pd.DataFrame(data['data'])\n",
    "results_df2 = pd.DataFrame(data2['data'])\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:05:27.468751Z",
     "start_time": "2021-04-25T02:05:27.462357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'allow_live_comments', 'author',\n",
       "       'author_flair_css_class', 'author_flair_richtext', 'author_flair_text',\n",
       "       'author_flair_type', 'author_fullname', 'author_patreon_flair',\n",
       "       'author_premium', 'awarders', 'can_mod_post', 'contest_mode',\n",
       "       'created_utc', 'domain', 'full_link', 'gallery_data', 'gildings', 'id',\n",
       "       'is_crosspostable', 'is_gallery', 'is_meta', 'is_original_content',\n",
       "       'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video',\n",
       "       'link_flair_background_color', 'link_flair_css_class',\n",
       "       'link_flair_richtext', 'link_flair_template_id', 'link_flair_text',\n",
       "       'link_flair_text_color', 'link_flair_type', 'locked', 'media_metadata',\n",
       "       'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18',\n",
       "       'parent_whitelist_status', 'permalink', 'pinned', 'pwls',\n",
       "       'retrieved_on', 'score', 'selftext', 'send_replies', 'spoiler',\n",
       "       'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers',\n",
       "       'subreddit_type', 'suggested_sort', 'thumbnail', 'thumbnail_height',\n",
       "       'thumbnail_width', 'title', 'total_awards_received', 'treatment_tags',\n",
       "       'upvote_ratio', 'url', 'url_overridden_by_dest', 'whitelist_status',\n",
       "       'wls', 'removed_by_category', 'post_hint', 'preview', 'media',\n",
       "       'media_embed', 'secure_media', 'secure_media_embed',\n",
       "       'author_flair_template_id', 'author_flair_text_color'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of metadata here. We probably will not need most of it.\n",
    "\n",
    "Here are the important tags we plan to use:\n",
    "\n",
    "* subreddit\n",
    "* selftext\n",
    "* title\n",
    "* created_utc\n",
    "* author\n",
    "* is_self (to filter out link-only posts)\n",
    "* score\n",
    "* num_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab just the metadata we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:05:30.235042Z",
     "start_time": "2021-04-25T02:05:30.231992Z"
    }
   },
   "outputs": [],
   "source": [
    "subfields = ['title', 'selftext', 'subreddit', 'created_utc', 'author', 'is_self', \\\n",
    "'score', 'num_comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:05:33.284101Z",
     "start_time": "2021-04-25T02:05:33.265603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>is_self</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Cars (2006), ‚ÄúThe King‚Äù Strip Weathers crashes in his final race, but makes it to the finish line. In 1992, NASCAR‚Äôs ‚ÄúKing,‚Äù Richard Petty (the voice of Strip Weathers in the Cars movies), cras...</td>\n",
       "      <td></td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>1619315293</td>\n",
       "      <td>October23rd2077</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Shrek 2 (2004) there's a portrait in Fairy Godmother's cottage depicting the cyclops from The Poison Apple with the caption \"After.\" This suggests that there's another portrait depicting \"Befor...</td>\n",
       "      <td></td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>1619314737</td>\n",
       "      <td>coolstevenn</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                     title  \\\n",
       "0  In Cars (2006), ‚ÄúThe King‚Äù Strip Weathers crashes in his final race, but makes it to the finish line. In 1992, NASCAR‚Äôs ‚ÄúKing,‚Äù Richard Petty (the voice of Strip Weathers in the Cars movies), cras...   \n",
       "1  In Shrek 2 (2004) there's a portrait in Fairy Godmother's cottage depicting the cyclops from The Poison Apple with the caption \"After.\" This suggests that there's another portrait depicting \"Befor...   \n",
       "\n",
       "  selftext     subreddit  created_utc           author  is_self  score  \\\n",
       "0           MovieDetails   1619315293  October23rd2077    False      1   \n",
       "1           MovieDetails   1619314737      coolstevenn    False      1   \n",
       "\n",
       "   num_comments  \n",
       "0             1  \n",
       "1             1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df[subfields]\n",
    "results_df2 = results_df2[subfields]\n",
    "results_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove any duplicate posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:05:37.036457Z",
     "start_time": "2021-04-25T02:05:37.017344Z"
    }
   },
   "outputs": [],
   "source": [
    "#dupes\n",
    "results_df.drop_duplicates(inplace=True)\n",
    "results_df2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also only want original text content here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:05:40.862660Z",
     "start_time": "2021-04-25T02:05:40.853904Z"
    }
   },
   "outputs": [],
   "source": [
    "#filter only for self posts\n",
    "results_df = results_df[results_df[\"is_self\"] == True]\n",
    "results_df2 = results_df2[results_df2['is_self']==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll grab the timestamp so that we can set before and after the post we want, to pull in our desired volume of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:05:43.200726Z",
     "start_time": "2021-04-25T02:05:43.186737Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    2021-04-24\n",
       "17    2021-04-24\n",
       "18    2021-04-24\n",
       "41    2021-04-24\n",
       "54    2021-04-23\n",
       "55    2021-04-23\n",
       "56    2021-04-23\n",
       "57    2021-04-23\n",
       "59    2021-04-23\n",
       "63    2021-04-23\n",
       "79    2021-04-23\n",
       "86    2021-04-23\n",
       "89    2021-04-23\n",
       "91    2021-04-23\n",
       "92    2021-04-23\n",
       "Name: timestamp, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert timestamp to a format we understand\n",
    "results_df['timestamp'] = results_df['created_utc'].map(dt.date.fromtimestamp)\n",
    "results_df2['timestamp'] = results_df2['created_utc'].map(dt.date.fromtimestamp)\n",
    "results_df['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:05:47.218991Z",
     "start_time": "2021-04-25T02:05:47.212972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we get a couple days' worth in a single pull."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up to pull @certain freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up our pull to be a bit more dynamic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:06:04.872868Z",
     "start_time": "2021-04-25T02:06:04.866352Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.pushshift.io/reddit/search/submission?subreddit=MovieDetails&size=100'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define endpoint\n",
    "base_url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "#update params\n",
    "subreddit = 'MovieDetails'\n",
    "size = 100\n",
    "\n",
    "#construct URL\n",
    "stem = f'{base_url}?subreddit={subreddit}&size={size}'\n",
    "stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:06:06.774151Z",
     "start_time": "2021-04-25T02:06:06.767570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem == url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add in a time component to loop over multiple days' worth of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:06:22.760110Z",
     "start_time": "2021-04-25T02:06:22.752833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.pushshift.io/reddit/search/submission?subreddit=MovieDetails&size=100&after=30d'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = 30\n",
    "url = f'{stem}&after={days}d'\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:08:23.066638Z",
     "start_time": "2021-04-25T02:08:20.356694Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2021-03-27\n",
       "1    2021-03-27\n",
       "2    2021-03-27\n",
       "3    2021-03-27\n",
       "4    2021-03-27\n",
       "Name: created_utc, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify output\n",
    "\n",
    "res=requests.get(url)\n",
    "assert res.status_code == 200\n",
    "json_data = res.json()\n",
    "\n",
    "results_df = pd.DataFrame(json_data['data'])[subfields]\n",
    "\n",
    "results_df[\n",
    "    'created_utc'].map(dt.date.fromtimestamp).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see somthing from as far back as a month ago, which is what we were expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:08:27.973289Z",
     "start_time": "2021-04-25T02:08:27.965069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:48:07.753902Z",
     "start_time": "2021-04-25T02:48:07.725071Z"
    }
   },
   "outputs": [],
   "source": [
    "#for loop to iterate through the pulls\n",
    "\n",
    "def fetch_posts(subreddit):\n",
    "\n",
    "#est. params\n",
    "    subreddit = 'MovieDetails'\n",
    "    \n",
    "    kind = 'submission' #post vs. comment -- Riley\n",
    "    \n",
    "#est url\n",
    "\n",
    "    base_url = f'https://api.pushshift.io/reddit/search/{kind}'\n",
    "\n",
    "    stem = f'{base_url}?subreddit={subreddit}&size=500'\n",
    "\n",
    "#vars\n",
    "\n",
    "    day_window =7\n",
    "    \n",
    "    n=3 #number of iters, after which the loop will stop;\n",
    "    #it will create n result df's\n",
    "    \n",
    "    posts = []\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        \n",
    "        URL = f'{stem}&after={i * day_window}d'\n",
    "        \n",
    "        print('Query from timeframe: ' + URL)\n",
    "        \n",
    "        res = requests.get(URL)\n",
    "        \n",
    "        assert res.status_code == 200\n",
    "        \n",
    "        json = res.json()['data']\n",
    "        \n",
    "        df = pd.DataFrame(json)[subfields]\n",
    "        \n",
    "        posts.append(df)\n",
    "        \n",
    "        time.sleep(1) #wait 1 s between requests\n",
    "        \n",
    "        #check post length\n",
    "        \n",
    "        print(len(posts))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:48:10.679434Z",
     "start_time": "2021-04-25T02:48:10.671832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:48:13.941520Z",
     "start_time": "2021-04-25T02:48:13.812855Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-16f65e8a7555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:25:50.656122Z",
     "start_time": "2021-04-25T02:25:50.636656Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b666bf274d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:48:37.880252Z",
     "start_time": "2021-04-25T02:48:17.688575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query from timeframe: https://api.pushshift.io/reddit/search/submission?subreddit=MovieDetails&size=500&after=7d\n",
      "1\n",
      "Query from timeframe: https://api.pushshift.io/reddit/search/submission?subreddit=MovieDetails&size=500&after=14d\n",
      "2\n",
      "Query from timeframe: https://api.pushshift.io/reddit/search/submission?subreddit=MovieDetails&size=500&after=21d\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>is_self</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Honda Civic ninjas in Cars 2(2011) are a nod to the Heist Civics seen in the beginning of The Fast and The Furious(2001)</td>\n",
       "      <td></td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>1617504536</td>\n",
       "      <td>Ranchdippingsauc</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In 'Under The Skin' (2013) the van Scarlett Johansson uses to hunt for men was equipped with multiple hidden cameras. So she actually drove around Glasgow picking up random strangers who had no id...</td>\n",
       "      <td></td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>1617506890</td>\n",
       "      <td>Schlappydog</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In City of God (2002), one of the actors, who used to be in a real gang, asked director Fernando Meirelles if the group was not going to pray like they always did before a shootout. Meirelles told...</td>\n",
       "      <td></td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>1617507107</td>\n",
       "      <td>lanzevedo</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Borderlands (film)</td>\n",
       "      <td></td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>1617510858</td>\n",
       "      <td>alizamessy</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My girlfriend realized that why Murph says \"It's traditional\" after saying \"Eureka\" (to which no one, including Topher Grace's character understands) is because the history books in their society ...</td>\n",
       "      <td></td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>1617512113</td>\n",
       "      <td>axc356</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                     title  \\\n",
       "0                                                                             The Honda Civic ninjas in Cars 2(2011) are a nod to the Heist Civics seen in the beginning of The Fast and The Furious(2001)   \n",
       "1  In 'Under The Skin' (2013) the van Scarlett Johansson uses to hunt for men was equipped with multiple hidden cameras. So she actually drove around Glasgow picking up random strangers who had no id...   \n",
       "2  In City of God (2002), one of the actors, who used to be in a real gang, asked director Fernando Meirelles if the group was not going to pray like they always did before a shootout. Meirelles told...   \n",
       "3                                                                                                                                                                                       Borderlands (film)   \n",
       "4  My girlfriend realized that why Murph says \"It's traditional\" after saying \"Eureka\" (to which no one, including Topher Grace's character understands) is because the history books in their society ...   \n",
       "\n",
       "  selftext     subreddit  created_utc            author  is_self  score  \\\n",
       "0           MovieDetails   1617504536  Ranchdippingsauc    False      1   \n",
       "1           MovieDetails   1617506890       Schlappydog    False      1   \n",
       "2           MovieDetails   1617507107         lanzevedo    False      1   \n",
       "3           MovieDetails   1617510858        alizamessy    False      1   \n",
       "4           MovieDetails   1617512113            axc356    False      1   \n",
       "\n",
       "   num_comments  \n",
       "0             5  \n",
       "1            33  \n",
       "2             8  \n",
       "3             0  \n",
       "4             2  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = fetch_posts(subreddit)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will concatenate all the output dataframes with our posts into one massive dataframe of all the collected posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:48:42.565021Z",
     "start_time": "2021-04-25T02:48:42.514296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'selftext', 'subreddit', 'created_utc', 'author', 'is_self',\n",
       "       'score', 'num_comments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:49:38.116118Z",
     "start_time": "2021-04-25T02:49:38.087223Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-91c583976e3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    304\u001b[0m     ):\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;34m\"first argument must be an iterable of pandas \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;34m\"objects, you passed an object of type \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "combined = pd.concat(df1, sort=False)\n",
    "print(combined.shape)\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat this process for our second subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.406378Z",
     "start_time": "2021-04-25T01:59:54.848Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(posts) #Get the list of posts into a dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.410796Z",
     "start_time": "2021-04-25T01:59:54.854Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#see, what we got!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at basic stats about our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.412760Z",
     "start_time": "2021-04-25T01:59:54.963Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.415146Z",
     "start_time": "2021-04-25T01:59:54.968Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.416923Z",
     "start_time": "2021-04-25T01:59:54.972Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand the density and usefulness of our content, by analyzing the volume of comments and looking for the richness of the text-heavy columns we are expecting.\n",
    "\n",
    "We are also going to see, whether there are any interesting prospective features for training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.420626Z",
     "start_time": "2021-04-25T01:59:55.083Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['is_original_content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.422955Z",
     "start_time": "2021-04-25T01:59:55.088Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['num_comments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.426945Z",
     "start_time": "2021-04-25T01:59:55.092Z"
    }
   },
   "outputs": [],
   "source": [
    "df['media_only'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.432612Z",
     "start_time": "2021-04-25T01:59:55.096Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['created_utc'].value_counts().unique #check for time stamps; replace this w/ groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.435159Z",
     "start_time": "2021-04-25T01:59:55.104Z"
    }
   },
   "outputs": [],
   "source": [
    "#check for post density\n",
    "df['selftext'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.437096Z",
     "start_time": "2021-04-25T01:59:55.109Z"
    }
   },
   "outputs": [],
   "source": [
    "df['selftext'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.439073Z",
     "start_time": "2021-04-25T01:59:55.114Z"
    }
   },
   "outputs": [],
   "source": [
    "df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.441024Z",
     "start_time": "2021-04-25T01:59:55.118Z"
    }
   },
   "outputs": [],
   "source": [
    "df['media'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.442969Z",
     "start_time": "2021-04-25T01:59:55.124Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['subreddit_subscribers'].value_counts().unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T02:00:24.444707Z",
     "start_time": "2021-04-25T01:59:55.129Z"
    }
   },
   "outputs": [],
   "source": [
    "df['upvote_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP & feature eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
